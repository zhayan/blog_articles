## 图像增广
翻转和裁剪
改变图像颜色的四个方面：亮度、对比度、饱和度和色调
高斯模糊
加噪声（点噪，块噪）

## fine-tuning
在源数据集（例如 ImageNet 数据集）上预训练神经网络模型，即 源模型。

创建一个新的神经网络模型，即 目标模型。这将复制源模型上的所有模型设计及其参数，但输出层除外。我们假定这些模型参数包含从源数据集中学到的知识，这些知识也将适用于目标数据集。我们还假设源模型的输出层与源数据集的标签密切相关；因此不在目标模型中使用该层。

向目标模型添加输出层，其输出数量是目标数据集中的类别数。然后随机初始化该层的模型参数。

在目标数据集（如椅子数据集）上训练目标模型。输出层将从头开始进行训练，而所有其他层的参数将根据源模型的参数进行微调。

通常，微调参数使用较小的学习率，而从头开始训练输出层可以使用更大的学习率。

## 锚框生成
假设输入图像的高度为  h ，宽度为  w 。 我们以图像的每个像素为中心生成不同形状的锚框：比例 为  s∈(0,1] ，宽高比（宽高比）为  r>0 。 那么锚框的宽度和高度分别是  ws√r  和  hs/√r 。

## IoU
交并比用于量化锚框覆盖准确度

## 标注训练数据的锚框
将真实边界框分配给锚框
为每个锚框标记分类和偏移量。 假设一个锚框  A  被分配了一个真实边界框  B 。 一方面，锚框  A  的类将被标记为与  B  相同。 另一方面，锚框  A  的偏移量将根据  B  和  A  中心坐标的相对位置、以及这两个框的相对大小进行标记。

## 非极大值抑制预测边界框
从  L  中选取置信度最高的预测边界框  B1  作为基准，然后将所有与  B1  的IoU 超过预定阈值  ϵ  的非基准预测边界框从  L  中移除。重复

## 多尺度锚框
将特征图的高度和宽度减小，检测大目标

## 单发多框检测（SSD）
多尺度：每个高和宽减半块由两个填充为  1  的  3×3  的卷积层、以及步幅为  2  的  2×2  最大汇聚层组成。
类别预测层
边界框预测层
连接多尺度的预测
第一种有关锚框类别的损失：我们可以简单地重用之前图像分类问题里一直使用的交叉熵损失函数来计算； 第二种有关正类锚框偏移量的损失：预测偏移量是一个回归问题。 但是，对于这个回归问题，我们在这里不使用平方损失，而是使用  L1  范数损失，即预测值和真实值之差的绝对值。
将锚框类别和偏移量的损失相加，以获得模型的最终损失函数。

## R-CNN
对输入图像使用 选择性搜索 来选取多个高质量的提议区域 。这些提议区域通常是在多个尺度下选取的，并具有不同的形状和大小。每个提议区域都将被标注类别和真实边界框。

选择一个预训练的卷积神经网络，并将其在输出层之前截断。将每个提议区域变形为网络需要的输入尺寸，并通过前向计算输出抽取的提议区域特征。

将每个提议区域的特征连同其标注的类别作为一个样本。训练多个支持向量机对目标分类，其中每个支持向量机用来判断样本是否属于某一个类别。

将每个提议区域的特征连同其标注的边界框作为一个样本，训练线性回归模型来预测真实边界框。

## Fast R-CNN
R-CNN 的主要性能瓶颈在于，对每个提议区域，卷积神经网络的前向计算是独立的，而没有共享计算。 由于这些区域通常有重叠，独立的特征抽取会导致重复的计算。 Fast R-CNN 对 R-CNN 的主要改进之一，是仅在整张图象上执行卷积神经网络的前向计算。
roi pool

## Faster R-CNN
为了较精确地检测目标结果，Fast R-CNN 模型通常需要在选择性搜索中生成大量的提议区域。 Faster R-CNN提出将选择性搜索替换为 区域提议网络（region proposal network），从而减少提议区域的生成数量，并保证目标检测的精度。

## Mask R-CNN
如果在训练集中还标注了每个目标在图像上的像素级位置，那么 Mask R-CNN [He et al., 2017] 能够有效地利用这些详尽的标注信息进一步提升目标检测的精度。